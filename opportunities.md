---
title: Opportunities
layout: page
hero_height: is-fullwidth
show_sidebar: false
---

<script src = "https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>

I am looking for students to work on CV tasks with ML.\\
If you are interested, feel free to drop me an email xxx@kcl.ac.uk.

- 10/2021 EU-H2020 research grant RESET  accepted !!  The grant topic is Restarting the Economy in Support of Environment, through Technology. It is a three-year project with Mark Mulligan from the Department of Geography, KCL and other five consortiums. I will RECRUIT one POSTDOC starting from 2021 working on machine learning algorithms in remote sensing imagery and time series data.

- 08/2021 [Closed] One post-doc position in computer vision and remote sensing imagery.
<i class="fa fa-info-circle" id="opportunity-05" style="color:red" aria-hidden="true"></i>

- 07/2021 [Closed] One UK PhD position on exploiting multi-task learning for endoscopic vision in robotic surgery.
<i class="fa fa-info-circle" id="opportunity-04" style="color:red" aria-hidden="true"></i>
- 06/2021 [Closed] One UK PhD position on visual recognition with minimal supervision.
<i class="fa fa-info-circle" id="opportunity-03" style="color:red" aria-hidden="true"></i>
- 05/2021 [Closed] One UK PhD position as a joint of BMEIS and NMS  at King's.
<i class="fa fa-info-circle" id="opportunity-02" style="color:red" aria-hidden="true"></i>
- 05/2021 [Closed] One UK PhD postion open at EPSRC CDT Smart Medical Imaging.
<i class="fa fa-info-circle" id="opportunity-01" style="color:red" aria-hidden="true"></i>



<div id="detail-05" class="modal">
  <div class="modal-background"></div>
  <div class="modal-card">
    <header class="modal-card-head">
      <p class="modal-card-title">Opportunity</p>
      <button class="delete" id="top-close-05" aria-label="close"></button>
    </header>
    <section class="modal-card-body">
      <div class="content">
        <h1>Title</h1>
        <p>Research Associate in Computer Vision/Remote Sensing Imagery</p>
        <h2>Content</h2>
        <p>The objective of this post-doc is to study deep learning methods for visual recognition of urban and rural scenes in remote sensing imagery. Key infrastructure types such as dams, reservoirs, roads, rails, trees etc will be identified and segmented in visual images; densities/distributions of these infrastructures over different areas will be analyzed.  The challenge lies in the recognition of both objects and stuffs in images, where the latter (e.g. reservoirs, trees) often do not have specific spatial extent or shape and is largely unexplored; furthermore, because of the utility of remote sensing imagery, the target infrastructures also differ in appearance and resolutions from their traditional observations.<br>
        <br>
        This post is part of the European H-2020 project ReSET. The PDRA will be supervised by Dr. Miaojing Shi in the Department of Informatics; and will also work closely with Prof. Mark Mulligan from the Department of Geography within the framework of ReSET. <br>
        <br>
        The post holder should have a PhD in a relevant field (Image Processing, Computer vision, Machine learning) and a good publication track records on high-quality conferences/journals; preferably have worked on projects such as image classification, semantic segmentation, and crowd counting; and have prior experiences working on remote sensing, time serials, and geographic data. <br>
        <br>
        This post will be offered on an a fixed-term contract for 12 months</p>
      </div>
    </section>
    <footer class="modal-card-foot">
        <button class="button" id="close-05">Close</button>
    </footer>
  </div>
</div>


<div id="detail-04" class="modal">
  <div class="modal-background"></div>
  <div class="modal-card">
    <header class="modal-card-head">
      <p class="modal-card-title">Opportunity</p>
      <button class="delete" id="top-close-04" aria-label="close"></button>
    </header>
    <section class="modal-card-body">
      <div class="content">
        <h1>Title</h1>
        <p> Exploiting multi-task learning for endoscopic vision in robotic surgery</p>
        <h2>Content</h2>
        <p>Multi-task learning is common in deep learning, where clear evidence shows that jointly learning correlated tasks can improve on individual performances. Notwithstanding, in reality, many tasks are processed independently. The reasons are manifold: 1) many tasks are not strongly correlated, benefits might be obtained for only one or none of the tasks in joint learning; 2) the scalability of learning multiple tasks is limited with the number of tasks in terms of both network optimization and practical implementation. Having a scalable and robust multi-task learning strategy however is very meaningful and of substantial potential in many real applications, i.e. endoscopic image processing. This project studies multi-task learning in endoscopic vision for robotic surgery with a particular focus on depth and optical flow estimation, surgical instrument detection and anatomy recognition, as well as surgical action recognition. The aim is to design effective multi-task learning strategies to improve the performance on all tasks.<br>
        <br>
        Candidates are requested to send an initial expression of interest to me (miaojing.shi@kcl.ac.uk ).</p>
        <p>
        <figure>
          <img src="https://lh5.googleusercontent.com/lK9qLa8ubsTqKe-PS9hNED3lAH9rJY9DiIVtMycBsqhOj9hzjAc062lyTSMelePxW_QJQqC4v0k7BFn5slPmAx9pNAmCVHcuHermaQ9IeXJx68Q2JN-_xqTnoSl2xJh_Fg=w1280">
        </figure>
        The target starting date is Oct. 2021. The PhD will be supervised by Dr Miaojing Shi and <a href="https://sites.google.com/site/tomvercauteren/"> Prof Tom Vercauteren</a>. Work will be carried out within the <a href="https://www.kcl.ac.uk/informatics"> Department of Informatics</a>, with access to <a href="https://www.surgerycdt.com/"> CDT Surgical & Interventional Engineering</a>, King’s College London.
        </p>
      </div>
    </section>
    <footer class="modal-card-foot">
        <button class="button" id="close-04">Close</button>
    </footer>
  </div>
</div>


<div id="detail-03" class="modal">
  <div class="modal-background"></div>
  <div class="modal-card">
    <header class="modal-card-head">
      <p class="modal-card-title">Opportunity</p>
      <button class="delete" id="top-close-03" aria-label="close"></button>
    </header>
    <section class="modal-card-body">
      <div class="content">
        <h1>Title</h1>
        <p>Visual recognition with limited supervision in deep learning context</p>
        <h2>Content</h2>
        <p>Details here: <a href="https://www.kcl.ac.uk/study/funding/visual-recognition-with-minimal-supervision-in-deep-learning"> https://www.kcl.ac.uk/study/funding/visual-recognition-with-minimal-supervision-in-deep-learning</a> <br>
        <br>
        The goal of this PhD is to study object detection/segmentation in images or video with limited supervision. This task will be placed into a setting where only image-level annotation is provided. To begin, additional supervision such as clicks, strokes, or bounding boxes may also be assumed. Towards the end of the PhD, the student is expected to work with datasets of mixed levels of supervision, including a harder, semi-supervised setting where there are only a few image-level labels as well as a large amount of unlabeled images. Few-shot learning is another challenging direction to explore. <br>
        <br>
        Several ideas can be investigated in the context of deep learning. For instance, generative adversarial learning can be employed to either augment the dataset or bridge the predicted detections with their ground truth. Recurrent neural networks can be applied to video segmentation in particular to localize and segment semantic parts across nearby frames. On unstructured image datasets, ideas like random-walk label propagation can be extended across pairs or groups of images. Deep metric learning and cross-category transfer learning can be studied in a few-shot scenario. <br>
        <br>
        The candidate should ideally have a master degree in Computer Science, Applied Mathematics or Electrical Engineering; solid mathematical background and programming skills; fluency in English language; preferably, prior experience in computer vision, machine learning and deep learning. <br>
        <br>
        This is a UK studentship for three years. The target starting date is Oct. 2021. The PhD will be supervised by Dr Miaojing Shi and Dr Michael Spratling. Work will be carried out within the Department of Informatics, King’s College London. More details can be found here: <a href="https://www.kcl.ac.uk/informatics/postgraduate/research-degrees"> https://www.kcl.ac.uk/informatics/postgraduate/research-degrees.</a> <br>
        <br>
        Application Instructions: Candidates are requested to send an initial expression of interest to me (miaojing.shi@kcl.ac.uk ) preferably with updated CV and motivation letter.
        </p>
      </div>
    </section>
    <footer class="modal-card-foot">
        <button class="button" id="close-03">Close</button>
    </footer>
  </div>
</div>


<div id="detail-02" class="modal">
  <div class="modal-background"></div>
  <div class="modal-card">
    <header class="modal-card-head">
      <p class="modal-card-title">Opportunity</p>
      <button class="delete" id="top-close-02" aria-label="close"></button>
    </header>
    <section class="modal-card-body">
      <div class="content">
        <h1>Title</h1>
        <p>One UK PhD position open as a joint of BMEIS and NMS at King's</p>
        <h2>Content</h2>
        <p>Details here: <a href="https://www.kcl.ac.uk/study/funding/fairness-in-ai-for-cardiac-imaging "> https://www.kcl.ac.uk/study/funding/fairness-in-ai-for-cardiac-imaging </a>
        </p>
      </div>
    </section>
    <footer class="modal-card-foot">
        <button class="button" id="close-02">Close</button>
    </footer>
  </div>
</div>

<div id="detail-01" class="modal">
  <div class="modal-background"></div>
  <div class="modal-card">
    <header class="modal-card-head">
      <p class="modal-card-title">Opportunity</p>
      <button class="delete" id="top-close-01" aria-label="close"></button>
    </header>
    <section class="modal-card-body">
      <div class="content">
        <h1>Title</h1>
        <p>AI-Enabled Assessment of Cardiac Function from Echocardiography </p>
        <h2>Content</h2>
        <p>Details here: <a href="https://www.imagingcdt.com/project/ai-enabled-assessment-of-cardiac-function-from-echocardiography ">  https://www.imagingcdt.com/project/ai-enabled-assessment-of-cardiac-function-from-echocardiography </a>
        </p>
      </div>
    </section>
    <footer class="modal-card-foot">
        <button class="button" id="close-01">Close</button>
    </footer>
  </div>
</div>


<script>
$("#opportunity-05").click(function() {
  $("#detail-05").addClass("is-active");  
});
$("#top-close-05").click(function() {
   $("#detail-05").removeClass("is-active");
});
$("#close-05").click(function() {
   $("#detail-05").removeClass("is-active");
});
$("#opportunity-04").click(function() {
  $("#detail-04").addClass("is-active");  
});
$("#top-close-04").click(function() {
   $("#detail-04").removeClass("is-active");
});
$("#close-04").click(function() {
   $("#detail-04").removeClass("is-active");
});
$("#opportunity-03").click(function() {
  $("#detail-03").addClass("is-active");  
});
$("#top-close-03").click(function() {
   $("#detail-03").removeClass("is-active");
});
$("#close-03").click(function() {
   $("#detail-03").removeClass("is-active");
});
$("#opportunity-02").click(function() {
  $("#detail-02").addClass("is-active");  
});
$("#top-close-02").click(function() {
   $("#detail-02").removeClass("is-active");
});
$("#close-02").click(function() {
   $("#detail-02").removeClass("is-active");
});
$("#opportunity-01").click(function() {
  $("#detail-01").addClass("is-active");  
});
$("#top-close-01").click(function() {
   $("#detail-01").removeClass("is-active");
});
$("#close-01").click(function() {
   $("#detail-01").removeClass("is-active");
});

</script>

